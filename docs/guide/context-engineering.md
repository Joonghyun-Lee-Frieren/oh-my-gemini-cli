# 컨텍스트 엔지니어링 가이드

> **"Cache Rules Everything Around Me"**
> — 에이전트 시대에도 캐시가 전부입니다.

---

## 컨텍스트 엔지니어링이란?

컨텍스트 엔지니어링(Context Engineering)은 대규모 언어 모델(LLM)과의 상호작용에서 **컨텍스트 윈도우를 체계적으로 설계하고 최적화하는 기술**입니다.

단순히 프롬프트를 잘 쓰는 "프롬프트 엔지니어링"을 넘어서, 시스템 프롬프트·도구 정의·대화 이력·외부 데이터를 **어떤 순서로, 어떤 구조로, 얼마나 안정적으로** 모델에 전달하느냐를 다룹니다.

### 왜 중요한가?

장기 실행 에이전트(long-running agent)에서는 매 턴마다 수만~수십만 토큰의 컨텍스트를 모델에 전송합니다. 이 과정에서:

- **비용**: 캐싱 없이는 동일한 토큰을 매번 다시 처리하여 비용이 기하급수적으로 증가
- **지연**: 캐시 미스 시 전체 컨텍스트를 처음부터 재연산
- **품질**: 컨텍스트 구조가 불안정하면 모델 응답의 일관성 저하

oh-my-gemini-cli(OmG)는 이 문제를 **프롬프트 캐싱 최적화**를 중심으로 해결합니다.

---

## 프롬프트 캐싱 이해하기

### 캐싱의 작동 원리

LLM API의 프롬프트 캐싱은 **접두사 매칭(Prefix Matching)** 방식으로 동작합니다. 이전 요청과 현재 요청의 컨텍스트가 **앞부분부터 동일한 구간**이 있으면, 해당 구간의 연산 결과를 재사용합니다.

```
이전 요청:  [시스템 프롬프트] [도구 정의] [대화 A] [대화 B]
현재 요청:  [시스템 프롬프트] [도구 정의] [대화 A] [대화 B] [대화 C]
            ├── 캐시 적중 (재사용) ─────────────────┤ ├── 새 연산 ┤
```

핵심 규칙: **접두사의 어떤 위치에서든 변경이 발생하면, 그 이후의 모든 캐시가 무효화됩니다.**

```
캐시 유지:  [A][B][C] → [A][B][C][D]        ✓ A,B,C 재사용
캐시 파괴:  [A][B][C] → [A][X][C][D]        ✗ B가 변경되어 B,C 모두 재연산
```

### 캐싱의 경제적 영향

| 지표 | 캐시 미적용 | 캐시 적용 (90%+) |
|------|------------|-------------------|
| 입력 토큰 비용 | 100% | ~25% (캐시 적중분은 할인) |
| 응답 지연 | 매 턴 전체 연산 | 캐시 적중분 즉시 처리 |
| 장기 세션 비용 | 턴 수에 비례하여 급증 | 거의 일정 유지 |

---

## 5가지 핵심 원칙

### 원칙 1: 접두사 안정성 유지 (Prefix Stability)

> 정적 콘텐츠는 앞에, 동적 콘텐츠는 뒤에.

접두사 캐싱의 특성상, 컨텍스트의 **앞부분이 안정적일수록** 캐시 적중률이 높아집니다.

#### 잘못된 구조 (캐시 파괴)

```
[변경되는 시간 정보] [시스템 프롬프트] [도구 정의] [대화]
 ↑ 매 턴 변경 → 뒤의 모든 캐시 무효화
```

#### 올바른 구조 (캐시 보존)

```
[시스템 프롬프트] [도구 정의] [GEMINI.md] [대화] [동적 데이터]
├── 거의 변경 안 됨 (캐시 안정) ────────┤ ├── 매 턴 변경 ┤
```

#### OmG의 구현

```
요청 구조 (캐싱 최적화 순서):

┌──────────────────────────────────┐  ← 전역 캐싱 (모든 세션 공유)
│  정적 시스템 프롬프트             │
│  도구 정의 (MCP 포함)            │
├──────────────────────────────────┤  ← 프로젝트 캐싱
│  GEMINI.md (프로젝트 컨텍스트)   │
├──────────────────────────────────┤  ← 세션 캐싱
│  세션 컨텍스트                    │
├──────────────────────────────────┤  ← 매 턴 변경 (새 토큰)
│  대화 메시지                      │
└──────────────────────────────────┘
```

OmG의 `context-layer.ts`는 이 계층 구조를 자동으로 관리합니다. 정적 레이어와 동적 레이어를 분리하여 캐시 적중률을 극대화합니다.

**관련 코드**: `src/context/context-layer.ts`, `src/context/prefix-optimizer.ts`

---

### 원칙 2: 도구 집합 불변 원칙 (Tool Invariance)

> 도구를 추가하거나 제거하면 캐시가 파괴됩니다.

도구 정의는 시스템 프롬프트 바로 다음, 즉 컨텍스트의 **앞부분**에 위치합니다. 도구를 동적으로 추가/제거하면 이 영역이 변경되어 **그 이후의 모든 캐시가 무효화**됩니다.

#### 문제 상황

```
턴 1: [시스템] [도구A, 도구B, 도구C] [대화...]
턴 2: [시스템] [도구A, 도구B]         [대화...]  ← 도구C 제거 → 캐시 파괴!
```

#### OmG의 해결책

**1. Plan Mode를 도구로 구현**

"읽기 전용 모드"를 위해 쓰기 도구를 제거하는 대신, `EnterPlanMode` / `ExitPlanMode`를 도구로 추가합니다. 도구 집합은 변하지 않으면서도 행동을 제어할 수 있습니다.

```
모든 도구 항상 포함 (캐시 안정):
├── read_file        ← 항상 활성
├── write_file       ← 항상 활성 (Plan Mode에서는 내부적으로 거부)
├── EnterPlanMode    ← Plan Mode 진입 (도구 추가/제거 없음)
├── ExitPlanMode     ← Plan Mode 종료
└── ...
```

**2. MCP 도구 지연 로딩**

MCP 서버가 제공하는 수십 개의 도구를 모두 등록하면 컨텍스트가 비대해집니다. OmG는 경량 스텁(stub)만 등록하고, 실제 필요 시 `ToolSearch`로 전체 스키마를 로드합니다.

```
등록된 도구 (항상 동일, 캐시 안정):
├── omg_state_stub     → 실제 호출 시 전체 스키마 로드
├── omg_memory_stub    → 실제 호출 시 전체 스키마 로드
├── omg_context_stub   → 실제 호출 시 전체 스키마 로드
└── omg_orchestrator_stub → 실제 호출 시 전체 스키마 로드
```

---

### 원칙 3: 모델 전환 대신 서브에이전트 (Sub-Agent Pattern)

> 프롬프트 캐시는 모델별로 고유합니다. 대화 중 모델을 전환하지 마세요.

하나의 세션에서 모델을 변경하면(예: Pro → Flash → Pro), 각 모델에 대한 캐시를 처음부터 새로 구축해야 합니다. 이는 캐싱의 이점을 완전히 상쇄합니다.

#### 잘못된 접근 (캐시 파괴)

```
턴 1: [Pro]   시스템 + 대화         → Pro 캐시 구축
턴 2: [Flash] 시스템 + 대화         → Flash 캐시를 처음부터 구축 (Pro 캐시 낭비)
턴 3: [Pro]   시스템 + 대화         → Pro 캐시를 다시 처음부터... 
```

#### OmG의 해결책: 서브에이전트 패턴

메인 세션의 모델은 절대 변경하지 않습니다. 다른 모델이 필요한 작업은 **별도의 서브에이전트**로 위임합니다.

```
메인 세션 (Gemini Pro) ──── Pro 캐시 계속 유지
  │
  ├─→ "이 코드를 구현해줘" (핸드오프)
  │     └─→ 서브에이전트 (Gemini Flash)
  │           ├── 자체 Flash 캐시 구축
  │           └── 결과만 반환
  │
  └─→ 메인 세션 계속 ──── Pro 캐시 여전히 유효!
```

#### 듀얼 모델 전략

| 역할 | 모델 | 이유 |
|------|------|------|
| Architect, Planner, Reviewer | Gemini Pro | 깊은 추론, 복잡한 설계 판단 |
| Executor, Quick | Gemini Flash | 빠른 코드 생성, 단순 편집 |
| Researcher | Pro (또는 외부 LLM) | 웹 검색, 문서 분석 |

각 에이전트는 자신만의 세션과 캐시를 유지하므로, 서로의 캐시를 파괴하지 않습니다.

**관련 코드**: `src/orchestrator/planner.ts`, `src/orchestrator/executor.ts`, `src/agents/agent-worker.ts`

---

### 원칙 4: 캐시 안전 컴팩션 (Cache-Safe Compaction)

> 컨텍스트를 압축할 때, 캐시를 보존하는 방식으로 압축하세요.

장기 실행 세션에서 대화가 길어지면 컨텍스트 윈도우(1M 토큰)에 가까워집니다. 이때 대화를 요약(컴팩션)해야 하는데, 단순 요약은 캐시를 파괴합니다.

#### 단순 요약의 문제

```
원본: [시스템][도구][대화1][대화2]...[대화50]
요약: [시스템][도구][요약문]
                    ↑ 원본과 다른 텍스트 → 캐시 파괴
```

#### OmG의 해결책: Cache-Safe Forking

부모 대화와 **동일한 접두사**를 사용하는 새로운 대화 분기를 생성합니다.

```
원본 대화:
  [시스템][도구][GEMINI.md][대화1]...[대화50]

Cache-Safe Fork:
  [시스템][도구][GEMINI.md][대화1]...[대화50] + [컴팩션 요청]
  ├── 전부 캐시 적중! ──────────────────────┤ ├── 새 토큰 ──┤
  
  → 모델이 요약을 생성
  → 요약 결과를 새 세션의 컨텍스트로 사용
```

핵심은 컴팩션 프롬프트를 **기존 대화의 끝에 추가**하는 것입니다. 이렇게 하면 기존 대화의 캐시를 100% 재활용하면서 요약을 생성할 수 있습니다.

**관련 코드**: `src/context/compaction.ts`

---

### 원칙 5: 시스템 리마인더 패턴 (System Reminders)

> 시스템 프롬프트를 직접 수정하지 마세요. 다음 메시지에 리마인더를 삽입하세요.

에이전트 실행 중 업데이트해야 하는 정보(현재 시간, 활성 파일 목록, 에러 상태 등)가 있습니다. 이를 시스템 프롬프트에 직접 삽입하면 캐시가 파괴됩니다.

#### 캐시 파괴하는 방법

```
시스템 프롬프트 v1: "You are a helpful assistant. Current time: 15:30"
시스템 프롬프트 v2: "You are a helpful assistant. Current time: 15:31"
                                                    ↑ 변경! → 전체 캐시 무효화
```

#### OmG의 해결책

시스템 프롬프트는 **절대 변경하지 않습니다**. 대신, 다음 턴의 사용자 메시지에 `<system-reminder>` 태그로 동적 정보를 삽입합니다.

```
시스템 프롬프트: "You are a helpful assistant."     ← 불변 (캐시 안정)
...
사용자 메시지:
  <system-reminder>
    현재 시간: 15:31
    활성 에이전트: Executor#1, Executor#2
    캐시 적중률: 94.2%
  </system-reminder>
  
  사용자의 실제 질문...
```

이 방식은 시스템 프롬프트의 캐시를 보존하면서도 모델에 최신 정보를 전달합니다. `<system-reminder>` 태그는 사용자 메시지의 일부이므로, 컨텍스트의 **끝부분(동적 영역)**에 위치하여 캐시에 영향을 주지 않습니다.

---

## OmG의 구현 아키텍처

### 컨텍스트 엔진 구조

```
src/context/
├── context-layer.ts       # 정적/동적 레이어 분리 관리
├── prefix-optimizer.ts    # 접두사 안정성 최적화
├── cache-manager.ts       # 캐시 적중률 모니터링 및 관리
└── compaction.ts          # 캐시 안전 컴팩션 (Cache-Safe Forking)
```

### 데이터 흐름

```
사용자 요청
    │
    ▼
┌─────────────────────┐
│ Context Layer        │
│ ┌─────────────────┐ │
│ │ Static Layer    │ │ ← 시스템 프롬프트, 도구 정의 (불변)
│ ├─────────────────┤ │
│ │ Project Layer   │ │ ← GEMINI.md, 프로젝트 설정 (저빈도 변경)
│ ├─────────────────┤ │
│ │ Session Layer   │ │ ← 세션 컨텍스트, 에이전트 상태
│ ├─────────────────┤ │
│ │ Dynamic Layer   │ │ ← 대화 메시지, system-reminder (매 턴)
│ └─────────────────┘ │
└──────────┬──────────┘
           │
           ▼
┌─────────────────────┐
│ Prefix Optimizer    │ → 접두사 안정성 검증, 캐시 브레이크 감지
└──────────┬──────────┘
           │
           ▼
┌─────────────────────┐
│ Cache Manager       │ → 캐시 적중률 모니터링, 알림
└──────────┬──────────┘
           │
           ▼
┌─────────────────────┐
│ Compaction Engine   │ → 윈도우 초과 시 Cache-Safe Fork 실행
└─────────────────────┘
```

### MCP 서버와의 통합

OmG는 4개의 MCP 서버를 통해 Gemini CLI에 컨텍스트 엔지니어링을 제공합니다:

| MCP 서버 | 역할 | 컨텍스트 레이어 |
|----------|------|-----------------|
| `omg_state` | 에이전트 상태 관리 | Session Layer |
| `omg_memory` | 프로젝트 메모리 | Project Layer |
| `omg_context` | 컨텍스트 엔진 인터페이스 | Static/Dynamic Layer |
| `omg_orchestrator` | 멀티 에이전트 오케스트레이션 | Session Layer |

---

## 캐시 모니터링 가이드

### 캐시 적중률 확인

```bash
omg status --cache
```

출력 예시:
```
Cache Hit Rate: 94.2%  (target: >90%)
Cache Misses Today: 12
Estimated Savings: $4.82

Breakdown:
  Static Layer:   99.8% hit  (system prompt, tools)
  Project Layer:  98.1% hit  (GEMINI.md)
  Session Layer:  91.4% hit  (session context)
  Dynamic Layer:  N/A        (always new)
```

### 목표 적중률

| 레이어 | 목표 | 경고 임계값 |
|--------|------|-------------|
| Static Layer | > 99% | < 98% |
| Project Layer | > 95% | < 90% |
| Session Layer | > 85% | < 80% |
| 전체 | > 90% | < 85% |

### 캐시 미스 진단

캐시 적중률이 목표 이하로 떨어지면, OmG는 이를 **인시던트**로 취급합니다.

```bash
# 캐시 미스 원인 분석
omg status --cache --verbose
```

출력 예시:
```
⚠ Cache miss detected at turn 42
  Cause: Tool definition changed (mcp_tool_3 added)
  Impact: 24,000 tokens re-computed
  Recommendation: Use tool stubs to maintain tool invariance
```

### 일반적인 캐시 미스 원인과 해결

| 원인 | 영향 | 해결 |
|------|------|------|
| 시스템 프롬프트 수정 | Static Layer 전체 무효화 | system-reminder 패턴 사용 |
| 도구 추가/제거 | Static Layer 이후 전체 무효화 | 도구 불변 원칙 준수 |
| 모델 전환 | 새 모델의 캐시 전무 | 서브에이전트 패턴 사용 |
| 단순 컴팩션 | Session Layer 이후 무효화 | Cache-Safe Forking 사용 |
| GEMINI.md 수정 | Project Layer 이후 무효화 | 세션 중 수정 자제, 필요 시 system-reminder |

### 대시보드에서 모니터링

ASCII 대시보드의 하단 상태바에서 실시간 캐시 적중률을 확인할 수 있습니다:

```
├─────────────────────────────────────────────────────────────────────┤
│  CTX Cache: 94.2% hit │ Tokens: 12.4k/1M │ Cost: $0.03            │
└─────────────────────────────────────────────────────────────────────┘
```

캐시 적중률이 경고 임계값 아래로 떨어지면 상태바 색상이 노란색(주의) 또는 빨간색(위험)으로 변경됩니다.

---

## 설정 최적화

### 권장 설정

```json
{
  "context": {
    "cache_monitoring": true,
    "cache_target_rate": 0.90,
    "compaction_strategy": "cache-safe",
    "prefix_stability": true
  }
}
```

### 설정 항목 설명

| 설정 | 기본값 | 설명 |
|------|--------|------|
| `cache_monitoring` | `true` | 캐시 적중률 모니터링 활성화 |
| `cache_target_rate` | `0.90` | 목표 캐시 적중률 (90%) |
| `compaction_strategy` | `"cache-safe"` | 컴팩션 전략 (`cache-safe` 또는 `simple`) |
| `prefix_stability` | `true` | 접두사 안정성 최적화 활성화 |

---

## 참고 자료

- [Claude Code 프롬프트 캐싱 교훈](https://news.hada.io/topic?id=26835) — OmG의 컨텍스트 엔지니어링 영감의 원천
- [Gemini API Prompt Caching](https://ai.google.dev/gemini-api/docs/caching) — Gemini의 프롬프트 캐싱 공식 문서
- [Anthropic Prompt Caching](https://docs.anthropic.com/en/docs/build-with-claude/prompt-caching) — 접두사 매칭 캐싱의 원리
